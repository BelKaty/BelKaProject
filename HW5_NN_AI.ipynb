{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BelKaty/BelKaProject/blob/main/HW5_NN_AI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "wC8PpbjTdBP3"
      },
      "outputs": [],
      "source": [
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('train_data.txt', 'r', encoding='utf-8') as f:\n",
        "    text = f.read()\n",
        "    text = text.replace('\\ufeff', '') # убираем первый невидимый символ\n",
        "    text = re.sub(r'[^А-я ]', '', text) # убираем все недопустимые символы"
      ],
      "metadata": {
        "id": "lDXMvGoqhoir"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "pjHXacrdiWzm",
        "outputId": "1269fb02-8895-47c7-f5dc-82591a0fb177"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Вы  лучший ответ на проблемы которые возникли в понедельникДумайте позитивно и верьте в свою способность достигать отличных результатовЕсли вы смогли в понедельник подняться с постели значит вы супер герой'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_J2b4nssifm6",
        "outputId": "63fbef77-9d30-40f3-8e58-c7c437253c6d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "205"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_characters = 34 #33 буквы + пробел"
      ],
      "metadata": {
        "id": "x3rLganvimNc"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.preprocessing.text import Tokenizer"
      ],
      "metadata": {
        "id": "gFnG4VGWi2ab"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer(num_words=num_characters, char_level=True)"
      ],
      "metadata": {
        "id": "TPtskSHMi61X"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.fit_on_texts(text)"
      ],
      "metadata": {
        "id": "CQtqVKoOi9zJ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenizer.word_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eLo6qJBYjAjq",
        "outputId": "037a90d4-c544-4bec-b579-b3bfd75d1954"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{' ': 1, 'о': 2, 'т': 3, 'е': 4, 'и': 5, 'в': 6, 'н': 7, 'с': 8, 'л': 9, 'п': 10, 'ь': 11, 'ы': 12, 'р': 13, 'а': 14, 'д': 15, 'у': 16, 'к': 17, 'з': 18, 'ч': 19, 'й': 20, 'м': 21, 'г': 22, 'б': 23, 'я': 24, 'ш': 25, 'ю': 26, 'х': 27}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inp_chars = 6 #\n",
        "data = tokenizer.texts_to_matrix(text)"
      ],
      "metadata": {
        "id": "6XJPRLv9jES_"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rDWVZpnXjG0z",
        "outputId": "9e161a3d-31d5-48e0-d1b4-c82a7af51fc3"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n = data.shape[0]-inp_chars\n",
        "n  #размер обучающего множества"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qrJ2cT-RjKA0",
        "outputId": "db6d4d86-b438-43b7-c664-705361bef931"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "199"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "H3Fd_wIdjMh6"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.array([data[i:i+inp_chars, :] for i in range(n)])\n",
        "Y = data[inp_chars:] #предсказание следующего символа"
      ],
      "metadata": {
        "id": "zSimljW9jNUC"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mCEbRdXkjP4X",
        "outputId": "c02e8ce1-35d4-4b92-bde4-c74c17cfe8d1"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "199"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y3b2arYQjTA8",
        "outputId": "2ddfe46a-7248-42b9-ae79-7a6de34e2607"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HpJ0pT9xjVdz",
        "outputId": "1249cd3a-32a6-450d-d857-60e382ba38f5"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import *\n",
        "from keras.models import Sequential"
      ],
      "metadata": {
        "id": "2tCMnTsfjYCJ"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Input((inp_chars, num_characters)))\n",
        "model.add(SimpleRNN(500, activation='tanh'))\n",
        "model.add(Dense(num_characters, activation='softmax'))\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QBlU3OFwjaLi",
        "outputId": "a8230941-e7c2-4bdb-9b78-fbc7f7ad67c5"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " simple_rnn (SimpleRNN)      (None, 500)               267500    \n",
            "                                                                 \n",
            " dense (Dense)               (None, 34)                17034     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 284534 (1.09 MB)\n",
            "Trainable params: 284534 (1.09 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import SimpleRNN\n"
      ],
      "metadata": {
        "id": "W33y6UhJQF0p"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
        "history = model.fit(X, Y, batch_size=32, epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BzftvQP-jfAg",
        "outputId": "2a95e169-0b43-4154-fee7-b77a23cb66f1"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "7/7 [==============================] - 1s 17ms/step - loss: 3.3780 - accuracy: 0.0955\n",
            "Epoch 2/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 2.4025 - accuracy: 0.3015\n",
            "Epoch 3/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 1.8917 - accuracy: 0.4523\n",
            "Epoch 4/100\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 1.5469 - accuracy: 0.5377\n",
            "Epoch 5/100\n",
            "7/7 [==============================] - 0s 21ms/step - loss: 1.2256 - accuracy: 0.6332\n",
            "Epoch 6/100\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 1.0224 - accuracy: 0.7035\n",
            "Epoch 7/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.8817 - accuracy: 0.7487\n",
            "Epoch 8/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.7450 - accuracy: 0.7940\n",
            "Epoch 9/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.6958 - accuracy: 0.8090\n",
            "Epoch 10/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.6085 - accuracy: 0.8191\n",
            "Epoch 11/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.5345 - accuracy: 0.8342\n",
            "Epoch 12/100\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.4154 - accuracy: 0.9196\n",
            "Epoch 13/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.3936 - accuracy: 0.9196\n",
            "Epoch 14/100\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.3264 - accuracy: 0.9598\n",
            "Epoch 15/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.3026 - accuracy: 0.9447\n",
            "Epoch 16/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.2692 - accuracy: 0.9447\n",
            "Epoch 17/100\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.3384 - accuracy: 0.9196\n",
            "Epoch 18/100\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.3496 - accuracy: 0.9246\n",
            "Epoch 19/100\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.3074 - accuracy: 0.9246\n",
            "Epoch 20/100\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.2768 - accuracy: 0.9548\n",
            "Epoch 21/100\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.2853 - accuracy: 0.9397\n",
            "Epoch 22/100\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.2726 - accuracy: 0.9196\n",
            "Epoch 23/100\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.2690 - accuracy: 0.9447\n",
            "Epoch 24/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.2956 - accuracy: 0.9246\n",
            "Epoch 25/100\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.2704 - accuracy: 0.9447\n",
            "Epoch 26/100\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.3248 - accuracy: 0.9296\n",
            "Epoch 27/100\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.2281 - accuracy: 0.9648\n",
            "Epoch 28/100\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.1532 - accuracy: 0.9698\n",
            "Epoch 29/100\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.1562 - accuracy: 0.9799\n",
            "Epoch 30/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.2096 - accuracy: 0.9598\n",
            "Epoch 31/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.2204 - accuracy: 0.9548\n",
            "Epoch 32/100\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.2348 - accuracy: 0.9447\n",
            "Epoch 33/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.2182 - accuracy: 0.9648\n",
            "Epoch 34/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.1530 - accuracy: 0.9598\n",
            "Epoch 35/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.0980 - accuracy: 0.9849\n",
            "Epoch 36/100\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.0817 - accuracy: 0.9849\n",
            "Epoch 37/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.0808 - accuracy: 0.9899\n",
            "Epoch 38/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.0863 - accuracy: 0.9799\n",
            "Epoch 39/100\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.0635 - accuracy: 0.9849\n",
            "Epoch 40/100\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.0920 - accuracy: 0.9849\n",
            "Epoch 41/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.0648 - accuracy: 0.9849\n",
            "Epoch 42/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.0596 - accuracy: 0.9849\n",
            "Epoch 43/100\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.0455 - accuracy: 0.9899\n",
            "Epoch 44/100\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.0432 - accuracy: 0.9899\n",
            "Epoch 45/100\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.0421 - accuracy: 0.9899\n",
            "Epoch 46/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.0506 - accuracy: 0.9899\n",
            "Epoch 47/100\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.0407 - accuracy: 0.9950\n",
            "Epoch 48/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.0497 - accuracy: 0.9899\n",
            "Epoch 49/100\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.0505 - accuracy: 0.9849\n",
            "Epoch 50/100\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.0456 - accuracy: 0.9849\n",
            "Epoch 51/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.0441 - accuracy: 0.9849\n",
            "Epoch 52/100\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.0341 - accuracy: 0.9899\n",
            "Epoch 53/100\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.0324 - accuracy: 0.9950\n",
            "Epoch 54/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.0308 - accuracy: 0.9950\n",
            "Epoch 55/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.0326 - accuracy: 0.9899\n",
            "Epoch 56/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.0358 - accuracy: 0.9899\n",
            "Epoch 57/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.0955 - accuracy: 0.9799\n",
            "Epoch 58/100\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.1070 - accuracy: 0.9849\n",
            "Epoch 59/100\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.1009 - accuracy: 0.9899\n",
            "Epoch 60/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.0639 - accuracy: 0.9899\n",
            "Epoch 61/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.0485 - accuracy: 0.9849\n",
            "Epoch 62/100\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.0458 - accuracy: 0.9899\n",
            "Epoch 63/100\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.0646 - accuracy: 0.9749\n",
            "Epoch 64/100\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.0453 - accuracy: 0.9899\n",
            "Epoch 65/100\n",
            "7/7 [==============================] - 0s 24ms/step - loss: 0.0308 - accuracy: 0.9849\n",
            "Epoch 66/100\n",
            "7/7 [==============================] - 0s 24ms/step - loss: 0.0398 - accuracy: 0.9899\n",
            "Epoch 67/100\n",
            "7/7 [==============================] - 0s 24ms/step - loss: 0.0316 - accuracy: 0.9899\n",
            "Epoch 68/100\n",
            "7/7 [==============================] - 0s 22ms/step - loss: 0.0554 - accuracy: 0.9849\n",
            "Epoch 69/100\n",
            "7/7 [==============================] - 0s 24ms/step - loss: 0.0336 - accuracy: 0.9899\n",
            "Epoch 70/100\n",
            "7/7 [==============================] - 0s 23ms/step - loss: 0.0346 - accuracy: 0.9899\n",
            "Epoch 71/100\n",
            "7/7 [==============================] - 0s 24ms/step - loss: 0.0222 - accuracy: 0.9950\n",
            "Epoch 72/100\n",
            "7/7 [==============================] - 0s 21ms/step - loss: 0.0292 - accuracy: 0.9950\n",
            "Epoch 73/100\n",
            "7/7 [==============================] - 0s 22ms/step - loss: 0.0246 - accuracy: 0.9950\n",
            "Epoch 74/100\n",
            "7/7 [==============================] - 0s 22ms/step - loss: 0.0238 - accuracy: 0.9950\n",
            "Epoch 75/100\n",
            "7/7 [==============================] - 0s 25ms/step - loss: 0.0220 - accuracy: 0.9950\n",
            "Epoch 76/100\n",
            "7/7 [==============================] - 0s 23ms/step - loss: 0.0225 - accuracy: 0.9950\n",
            "Epoch 77/100\n",
            "7/7 [==============================] - 0s 22ms/step - loss: 0.0205 - accuracy: 0.9950\n",
            "Epoch 78/100\n",
            "7/7 [==============================] - 0s 24ms/step - loss: 0.0221 - accuracy: 0.9950\n",
            "Epoch 79/100\n",
            "7/7 [==============================] - 0s 24ms/step - loss: 0.0223 - accuracy: 0.9950\n",
            "Epoch 80/100\n",
            "7/7 [==============================] - 0s 25ms/step - loss: 0.0344 - accuracy: 0.9849\n",
            "Epoch 81/100\n",
            "7/7 [==============================] - 0s 23ms/step - loss: 0.0307 - accuracy: 0.9899\n",
            "Epoch 82/100\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.0218 - accuracy: 0.9950\n",
            "Epoch 83/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.0212 - accuracy: 0.9950\n",
            "Epoch 84/100\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.0183 - accuracy: 0.9950\n",
            "Epoch 85/100\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.0250 - accuracy: 0.9899\n",
            "Epoch 86/100\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.0234 - accuracy: 0.9899\n",
            "Epoch 87/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.0200 - accuracy: 0.9950\n",
            "Epoch 88/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.0192 - accuracy: 0.9950\n",
            "Epoch 89/100\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.0212 - accuracy: 0.9950\n",
            "Epoch 90/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.0462 - accuracy: 0.9950\n",
            "Epoch 91/100\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.0531 - accuracy: 0.9950\n",
            "Epoch 92/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.0453 - accuracy: 0.9950\n",
            "Epoch 93/100\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.0285 - accuracy: 0.9950\n",
            "Epoch 94/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.0192 - accuracy: 0.9950\n",
            "Epoch 95/100\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.0188 - accuracy: 0.9950\n",
            "Epoch 96/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.0175 - accuracy: 0.9950\n",
            "Epoch 97/100\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.0176 - accuracy: 0.9899\n",
            "Epoch 98/100\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.0226 - accuracy: 0.9899\n",
            "Epoch 99/100\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.0160 - accuracy: 0.9950\n",
            "Epoch 100/100\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.0163 - accuracy: 0.9899\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def buildPhrase(inp_str, str_len = 50):\n",
        "  for i in range(str_len):\n",
        "    x = []\n",
        "    for j in range(i, i+inp_chars):\n",
        "      x.append(tokenizer.texts_to_matrix(inp_str[j])) # преобразуем символы в One-Hot-encoding\n",
        "\n",
        "    x = np.array(x)\n",
        "    inp = x.reshape(1, inp_chars, num_characters)\n",
        "\n",
        "    pred = model.predict( inp ) # предсказываем OHE четвертого символа\n",
        "    d = tokenizer.index_word[pred.argmax(axis=1)[0]] # получаем ответ в символьном представлении\n",
        "\n",
        "    inp_str += d # дописываем строку\n",
        "\n",
        "  return inp_str"
      ],
      "metadata": {
        "id": "S8i4Oyu8jkNV"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res = buildPhrase(\"утренн\")\n",
        "print(res)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fbvDV2skjo2g",
        "outputId": "6859615d-9f6a-435e-abc8-484277ada6e3"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 168ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "утренновтввд  а гяислптс пориеев ы нпчерьертв свыю споло\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Слова"
      ],
      "metadata": {
        "id": "TVcmjybyjvdO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, SimpleRNN, Dense"
      ],
      "metadata": {
        "id": "6x4sHnKSJeFi"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('train_data.txt', 'r', encoding='utf-8') as f:\n",
        "    texts = f.read()\n",
        "    texts = texts.replace('\\ufeff', '')"
      ],
      "metadata": {
        "id": "Pm5MfQ1qEDXt"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "54KaFLVoQHsL",
        "outputId": "c4060edb-62f3-453a-833b-5c794108fdae"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Вы — лучший ответ на проблемы, которые возникли в понедельник.\\nДумайте позитивно и верьте в свою способность достигать отличных результатов.\\nЕсли вы смогли в понедельник подняться с постели, значит вы супер герой.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "maxWordsCount = 1000\n",
        "tokenizer = Tokenizer(num_words=maxWordsCount, filters='!–\" —#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n\\r«»', lower=True, split=' ', char_level=False)\n",
        "\n",
        "tokenizer.fit_on_texts([texts])"
      ],
      "metadata": {
        "id": "YoP6dxr8BZdL"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequences = tokenizer.texts_to_sequences([texts])[0]\n",
        "vocab_size = len(tokenizer.word_index) + 1"
      ],
      "metadata": {
        "id": "DHjJMcuqMHyt"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tvvP37PZQL1M",
        "outputId": "82f927ff-b308-491a-aba2-c23d272795ed"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1,\n",
              " 4,\n",
              " 5,\n",
              " 6,\n",
              " 7,\n",
              " 8,\n",
              " 9,\n",
              " 2,\n",
              " 3,\n",
              " 10,\n",
              " 11,\n",
              " 12,\n",
              " 13,\n",
              " 2,\n",
              " 14,\n",
              " 15,\n",
              " 16,\n",
              " 17,\n",
              " 18,\n",
              " 19,\n",
              " 1,\n",
              " 20,\n",
              " 2,\n",
              " 3,\n",
              " 21,\n",
              " 22,\n",
              " 23,\n",
              " 24,\n",
              " 1,\n",
              " 25,\n",
              " 26]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YqS7F3KsQPX8",
        "outputId": "713fc540-254b-4bc8-b7e8-f97a425bbb12"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "27"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inp_words = 3\n",
        "X = []\n",
        "Y = []\n",
        "for i in range(len(sequences) - inp_words):\n",
        "    X.append(sequences[i:i + inp_words])\n",
        "    Y.append(sequences[i + inp_words])\n",
        "\n",
        "X = np.array(X)\n",
        "Y = np.array(Y)"
      ],
      "metadata": {
        "id": "t8ZM63GyJoia"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LYjsJRx_PqT0",
        "outputId": "6ff7c674-4f6f-4bb9-fac9-4171f8de80f8"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1,  4,  5],\n",
              "       [ 4,  5,  6],\n",
              "       [ 5,  6,  7],\n",
              "       [ 6,  7,  8],\n",
              "       [ 7,  8,  9],\n",
              "       [ 8,  9,  2],\n",
              "       [ 9,  2,  3],\n",
              "       [ 2,  3, 10],\n",
              "       [ 3, 10, 11],\n",
              "       [10, 11, 12],\n",
              "       [11, 12, 13],\n",
              "       [12, 13,  2],\n",
              "       [13,  2, 14],\n",
              "       [ 2, 14, 15],\n",
              "       [14, 15, 16],\n",
              "       [15, 16, 17],\n",
              "       [16, 17, 18],\n",
              "       [17, 18, 19],\n",
              "       [18, 19,  1],\n",
              "       [19,  1, 20],\n",
              "       [ 1, 20,  2],\n",
              "       [20,  2,  3],\n",
              "       [ 2,  3, 21],\n",
              "       [ 3, 21, 22],\n",
              "       [21, 22, 23],\n",
              "       [22, 23, 24],\n",
              "       [23, 24,  1],\n",
              "       [24,  1, 25]])"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KtHB4wdlPs_5",
        "outputId": "c03eb6fe-c2e5-49da-d3c8-ec8c4c04c380"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 6,  7,  8,  9,  2,  3, 10, 11, 12, 13,  2, 14, 15, 16, 17, 18, 19,\n",
              "        1, 20,  2,  3, 21, 22, 23, 24,  1, 25, 26])"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential([\n",
        "    Embedding(vocab_size, 50, input_length=inp_words),\n",
        "    SimpleRNN(128),\n",
        "    Dense(vocab_size, activation='softmax')\n",
        "])"
      ],
      "metadata": {
        "id": "3giKe_EZJzFO"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "NrRSGvQpJ3jf"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X, Y, batch_size=32, epochs=20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5WTO4pylMfr6",
        "outputId": "5706678e-0050-42e0-d933-db4e218a5b78"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1/1 [==============================] - 1s 1s/step - loss: 3.2866 - accuracy: 0.0357\n",
            "Epoch 2/20\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 3.2560 - accuracy: 0.1429\n",
            "Epoch 3/20\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 3.2253 - accuracy: 0.3214\n",
            "Epoch 4/20\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 3.1942 - accuracy: 0.4643\n",
            "Epoch 5/20\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 3.1626 - accuracy: 0.6071\n",
            "Epoch 6/20\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 3.1302 - accuracy: 0.6786\n",
            "Epoch 7/20\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 3.0967 - accuracy: 0.7500\n",
            "Epoch 8/20\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 3.0620 - accuracy: 0.7857\n",
            "Epoch 9/20\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 3.0258 - accuracy: 0.8214\n",
            "Epoch 10/20\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.9878 - accuracy: 0.8214\n",
            "Epoch 11/20\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.9479 - accuracy: 0.8214\n",
            "Epoch 12/20\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.9057 - accuracy: 0.8214\n",
            "Epoch 13/20\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 2.8611 - accuracy: 0.8214\n",
            "Epoch 14/20\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 2.8138 - accuracy: 0.8214\n",
            "Epoch 15/20\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 2.7636 - accuracy: 0.8214\n",
            "Epoch 16/20\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 2.7103 - accuracy: 0.8571\n",
            "Epoch 17/20\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.6536 - accuracy: 0.8571\n",
            "Epoch 18/20\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 2.5935 - accuracy: 0.8571\n",
            "Epoch 19/20\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.5297 - accuracy: 0.8571\n",
            "Epoch 20/20\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 2.4621 - accuracy: 0.8571\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from keras.preprocessing.sequence import pad_sequences"
      ],
      "metadata": {
        "id": "ZJKo9D1XNOJn"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def buildPhrase(text, model, tokenizer, max_len=20):\n",
        "    result = text.lower()\n",
        "    input_text = text\n",
        "    for _ in range(max_len):\n",
        "        sequence = tokenizer.texts_to_sequences([input_text])[0]\n",
        "        sequence = pad_sequences([sequence], maxlen=inp_words, padding='pre')\n",
        "        pred = model.predict(sequence)\n",
        "        pred_index = np.argmax(pred)\n",
        "        pred_word = tokenizer.index_word[pred_index]\n",
        "        result += \" \" + pred_word\n",
        "        input_text = input_text.split()[1:] + [pred_word]\n",
        "        input_text = ' '.join(input_text)\n",
        "    return result"
      ],
      "metadata": {
        "id": "K8rFYptwMmoR"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "initial_text = \"позитив добавляет годы\"\n",
        "predicted_phrase = buildPhrase(initial_text, model, tokenizer)\n",
        "print(predicted_phrase)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SvqS4gkXMqxJ",
        "outputId": "c16a4b48-6242-463a-a622-9c5212aae940"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 172ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "позитив добавляет годы понедельник понедельник понедельник в в понедельник понедельник позитивно в понедельник в позитивно понедельник понедельник в в понедельник понедельник позитивно в\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "В данном коде реализована функция buildPhrase, которая использует рекуррентную нейронную сеть для создания последовательности слов на основе заданного текста. Основные этапы выполнения этой функции включают:\n",
        "\n",
        "Подготовку входных данных: Исходный текст приводится к нижнему регистру для стандартизации данных и токенизируется с использованием токенизатора, связанного с моделью.\n",
        "\n",
        "Генерацию слов: Затем осуществляется цикл, в котором предсказывается следующее слово в последовательности. Текущая последовательность слов преобразуется в токены и производится предсказание с помощью модели.\n",
        "\n",
        "Обновление данных: Предсказанное слово добавляется к сгенерированной последовательности, затем входной текст обновляется путем удаления первого слова и добавления предсказанного.\n",
        "\n",
        "Завершение цикла: Этот процесс повторяется до достижения заданной длины последовательности или критерия останова.\n",
        "\n",
        "Возврат результата: В конце функции возвращается сгенерированная последовательность слов.\n",
        "\n",
        "Таким образом, функция buildPhrase эффективно использует рекуррентную нейронную сеть для генерации текста на основе обученных данных и представляет собой удобный инструмент для автоматического создания текста с помощью модели и токенизатора."
      ],
      "metadata": {
        "id": "eYCr2As0xfXo"
      }
    }
  ]
}