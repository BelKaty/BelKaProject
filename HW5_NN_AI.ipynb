{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BelKaty/BelKaProject/blob/main/HW5_NN_AI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "wC8PpbjTdBP3"
      },
      "outputs": [],
      "source": [
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('train_data.txt', 'r', encoding='utf-8') as f:\n",
        "    text = f.read()\n",
        "    text = text.replace('\\ufeff', '') # убираем первый невидимый символ\n",
        "    text = re.sub(r'[^А-я ]', '', text) # убираем все недопустимые символы"
      ],
      "metadata": {
        "id": "lDXMvGoqhoir"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "pjHXacrdiWzm",
        "outputId": "9c91ef12-561a-4169-efa6-f531be7eb046"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Вы  лучший ответ на проблемы которые возникли в понедельникДумайте позитивно и верьте в свою способность достигать отличных результатовЕсли вы смогли в понедельник подняться с постели значит вы супер герой'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_J2b4nssifm6",
        "outputId": "18f1f522-dddf-4e47-b9a6-4a3872dfc791"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "205"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_characters = 34 #33 буквы + пробел"
      ],
      "metadata": {
        "id": "x3rLganvimNc"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.preprocessing.text import Tokenizer"
      ],
      "metadata": {
        "id": "gFnG4VGWi2ab"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer(num_words=num_characters, char_level=True)"
      ],
      "metadata": {
        "id": "TPtskSHMi61X"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.fit_on_texts(text)"
      ],
      "metadata": {
        "id": "CQtqVKoOi9zJ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenizer.word_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eLo6qJBYjAjq",
        "outputId": "fb9d0532-a26a-4244-e0d6-e129b703e426"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{' ': 1, 'о': 2, 'т': 3, 'е': 4, 'и': 5, 'в': 6, 'н': 7, 'с': 8, 'л': 9, 'п': 10, 'ь': 11, 'ы': 12, 'р': 13, 'а': 14, 'д': 15, 'у': 16, 'к': 17, 'з': 18, 'ч': 19, 'й': 20, 'м': 21, 'г': 22, 'б': 23, 'я': 24, 'ш': 25, 'ю': 26, 'х': 27}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inp_chars = 6 #\n",
        "data = tokenizer.texts_to_matrix(text)"
      ],
      "metadata": {
        "id": "6XJPRLv9jES_"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rDWVZpnXjG0z",
        "outputId": "bba5e6ca-29ab-4f1e-99ab-bb016e7bbe8b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n = data.shape[0]-inp_chars\n",
        "n  #размер обучающего множества"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qrJ2cT-RjKA0",
        "outputId": "4352ea37-aae9-4783-9342-12f317a0419f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "199"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "H3Fd_wIdjMh6"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.array([data[i:i+inp_chars, :] for i in range(n)])\n",
        "Y = data[inp_chars:] #предсказание следующего символа"
      ],
      "metadata": {
        "id": "zSimljW9jNUC"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mCEbRdXkjP4X",
        "outputId": "343dfd12-c2ed-4d19-b7b0-735475d39a9a"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "199"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y3b2arYQjTA8",
        "outputId": "ec710aca-bdd5-4e89-c918-4e10f5ef8ecc"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HpJ0pT9xjVdz",
        "outputId": "433e4429-4dd5-4ca9-b1cd-1494c34c5f56"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import *\n",
        "from keras.models import Sequential"
      ],
      "metadata": {
        "id": "2tCMnTsfjYCJ"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Input((inp_chars, num_characters)))\n",
        "model.add(SimpleRNN(500, activation='tanh'))\n",
        "model.add(Dense(num_characters, activation='softmax'))\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QBlU3OFwjaLi",
        "outputId": "4777baaf-357c-4acb-9233-4b1ce69daa3f"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " simple_rnn (SimpleRNN)      (None, 500)               267500    \n",
            "                                                                 \n",
            " dense (Dense)               (None, 34)                17034     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 284534 (1.09 MB)\n",
            "Trainable params: 284534 (1.09 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import SimpleRNN\n"
      ],
      "metadata": {
        "id": "W33y6UhJQF0p"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
        "history = model.fit(X, Y, batch_size=32, epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BzftvQP-jfAg",
        "outputId": "5b0061a2-1697-473c-a93f-f3a8f5f6ba6f"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "7/7 [==============================] - 5s 41ms/step - loss: 3.4221 - accuracy: 0.0503\n",
            "Epoch 2/100\n",
            "7/7 [==============================] - 0s 36ms/step - loss: 2.4384 - accuracy: 0.3518\n",
            "Epoch 3/100\n",
            "7/7 [==============================] - 0s 28ms/step - loss: 1.9234 - accuracy: 0.4573\n",
            "Epoch 4/100\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 1.5623 - accuracy: 0.5578\n",
            "Epoch 5/100\n",
            "7/7 [==============================] - 0s 31ms/step - loss: 1.2577 - accuracy: 0.5779\n",
            "Epoch 6/100\n",
            "7/7 [==============================] - 0s 52ms/step - loss: 1.0382 - accuracy: 0.6734\n",
            "Epoch 7/100\n",
            "7/7 [==============================] - 0s 56ms/step - loss: 0.9072 - accuracy: 0.7538\n",
            "Epoch 8/100\n",
            "7/7 [==============================] - 0s 34ms/step - loss: 0.7498 - accuracy: 0.8040\n",
            "Epoch 9/100\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.7271 - accuracy: 0.8090\n",
            "Epoch 10/100\n",
            "7/7 [==============================] - 0s 32ms/step - loss: 0.7331 - accuracy: 0.8141\n",
            "Epoch 11/100\n",
            "7/7 [==============================] - 0s 26ms/step - loss: 0.5994 - accuracy: 0.8643\n",
            "Epoch 12/100\n",
            "7/7 [==============================] - 0s 36ms/step - loss: 0.5891 - accuracy: 0.8442\n",
            "Epoch 13/100\n",
            "7/7 [==============================] - 0s 31ms/step - loss: 0.5817 - accuracy: 0.8241\n",
            "Epoch 14/100\n",
            "7/7 [==============================] - 0s 41ms/step - loss: 0.4702 - accuracy: 0.8844\n",
            "Epoch 15/100\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.4550 - accuracy: 0.8995\n",
            "Epoch 16/100\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 0.4494 - accuracy: 0.8894\n",
            "Epoch 17/100\n",
            "7/7 [==============================] - 0s 50ms/step - loss: 0.3998 - accuracy: 0.9296\n",
            "Epoch 18/100\n",
            "7/7 [==============================] - 0s 41ms/step - loss: 0.3627 - accuracy: 0.9246\n",
            "Epoch 19/100\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.2771 - accuracy: 0.9397\n",
            "Epoch 20/100\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.2786 - accuracy: 0.9598\n",
            "Epoch 21/100\n",
            "7/7 [==============================] - 0s 43ms/step - loss: 0.2175 - accuracy: 0.9548\n",
            "Epoch 22/100\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 0.1978 - accuracy: 0.9749\n",
            "Epoch 23/100\n",
            "7/7 [==============================] - 0s 34ms/step - loss: 0.1665 - accuracy: 0.9698\n",
            "Epoch 24/100\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.1860 - accuracy: 0.9548\n",
            "Epoch 25/100\n",
            "7/7 [==============================] - 0s 36ms/step - loss: 0.2459 - accuracy: 0.9397\n",
            "Epoch 26/100\n",
            "7/7 [==============================] - 0s 31ms/step - loss: 0.2417 - accuracy: 0.9648\n",
            "Epoch 27/100\n",
            "7/7 [==============================] - 0s 33ms/step - loss: 0.2110 - accuracy: 0.9698\n",
            "Epoch 28/100\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 0.1514 - accuracy: 0.9698\n",
            "Epoch 29/100\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.1436 - accuracy: 0.9799\n",
            "Epoch 30/100\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.1109 - accuracy: 0.9799\n",
            "Epoch 31/100\n",
            "7/7 [==============================] - 0s 35ms/step - loss: 0.0928 - accuracy: 0.9899\n",
            "Epoch 32/100\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.0804 - accuracy: 0.9899\n",
            "Epoch 33/100\n",
            "7/7 [==============================] - 0s 53ms/step - loss: 0.0708 - accuracy: 0.9899\n",
            "Epoch 34/100\n",
            "7/7 [==============================] - 0s 64ms/step - loss: 0.0717 - accuracy: 0.9950\n",
            "Epoch 35/100\n",
            "7/7 [==============================] - 0s 53ms/step - loss: 0.1010 - accuracy: 0.9749\n",
            "Epoch 36/100\n",
            "7/7 [==============================] - 0s 56ms/step - loss: 0.0756 - accuracy: 0.9899\n",
            "Epoch 37/100\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.1054 - accuracy: 0.9749\n",
            "Epoch 38/100\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.0785 - accuracy: 0.9799\n",
            "Epoch 39/100\n",
            "7/7 [==============================] - 0s 52ms/step - loss: 0.0808 - accuracy: 0.9799\n",
            "Epoch 40/100\n",
            "7/7 [==============================] - 0s 49ms/step - loss: 0.0653 - accuracy: 0.9849\n",
            "Epoch 41/100\n",
            "7/7 [==============================] - 0s 56ms/step - loss: 0.0541 - accuracy: 0.9899\n",
            "Epoch 42/100\n",
            "7/7 [==============================] - 0s 46ms/step - loss: 0.0570 - accuracy: 0.9849\n",
            "Epoch 43/100\n",
            "7/7 [==============================] - 0s 58ms/step - loss: 0.0492 - accuracy: 0.9899\n",
            "Epoch 44/100\n",
            "7/7 [==============================] - 0s 54ms/step - loss: 0.0581 - accuracy: 0.9799\n",
            "Epoch 45/100\n",
            "7/7 [==============================] - 0s 35ms/step - loss: 0.0684 - accuracy: 0.9799\n",
            "Epoch 46/100\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 0.0452 - accuracy: 0.9849\n",
            "Epoch 47/100\n",
            "7/7 [==============================] - 0s 43ms/step - loss: 0.0959 - accuracy: 0.9849\n",
            "Epoch 48/100\n",
            "7/7 [==============================] - 0s 40ms/step - loss: 0.0561 - accuracy: 0.9849\n",
            "Epoch 49/100\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 0.0757 - accuracy: 0.9749\n",
            "Epoch 50/100\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 0.1593 - accuracy: 0.9749\n",
            "Epoch 51/100\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 0.2809 - accuracy: 0.9447\n",
            "Epoch 52/100\n",
            "7/7 [==============================] - 0s 23ms/step - loss: 0.3370 - accuracy: 0.9397\n",
            "Epoch 53/100\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 0.2023 - accuracy: 0.9497\n",
            "Epoch 54/100\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 0.1510 - accuracy: 0.9598\n",
            "Epoch 55/100\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 0.1637 - accuracy: 0.9548\n",
            "Epoch 56/100\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 0.1463 - accuracy: 0.9698\n",
            "Epoch 57/100\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 0.1042 - accuracy: 0.9749\n",
            "Epoch 58/100\n",
            "7/7 [==============================] - 0s 22ms/step - loss: 0.3445 - accuracy: 0.9246\n",
            "Epoch 59/100\n",
            "7/7 [==============================] - 0s 22ms/step - loss: 0.3217 - accuracy: 0.9296\n",
            "Epoch 60/100\n",
            "7/7 [==============================] - 0s 21ms/step - loss: 0.2144 - accuracy: 0.9598\n",
            "Epoch 61/100\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 0.2044 - accuracy: 0.9397\n",
            "Epoch 62/100\n",
            "7/7 [==============================] - 0s 21ms/step - loss: 0.1920 - accuracy: 0.9397\n",
            "Epoch 63/100\n",
            "7/7 [==============================] - 0s 21ms/step - loss: 0.1134 - accuracy: 0.9749\n",
            "Epoch 64/100\n",
            "7/7 [==============================] - 0s 22ms/step - loss: 0.1209 - accuracy: 0.9749\n",
            "Epoch 65/100\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 0.2110 - accuracy: 0.9447\n",
            "Epoch 66/100\n",
            "7/7 [==============================] - 0s 24ms/step - loss: 0.1221 - accuracy: 0.9749\n",
            "Epoch 67/100\n",
            "7/7 [==============================] - 0s 21ms/step - loss: 0.0841 - accuracy: 0.9799\n",
            "Epoch 68/100\n",
            "7/7 [==============================] - 0s 21ms/step - loss: 0.0561 - accuracy: 0.9849\n",
            "Epoch 69/100\n",
            "7/7 [==============================] - 0s 21ms/step - loss: 0.0608 - accuracy: 0.9849\n",
            "Epoch 70/100\n",
            "7/7 [==============================] - 0s 21ms/step - loss: 0.0539 - accuracy: 0.9849\n",
            "Epoch 71/100\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 0.0359 - accuracy: 0.9950\n",
            "Epoch 72/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.0388 - accuracy: 0.9849\n",
            "Epoch 73/100\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 0.0370 - accuracy: 0.9899\n",
            "Epoch 74/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.0305 - accuracy: 0.9899\n",
            "Epoch 75/100\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.0467 - accuracy: 0.9899\n",
            "Epoch 76/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.0553 - accuracy: 0.9899\n",
            "Epoch 77/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.0373 - accuracy: 0.9899\n",
            "Epoch 78/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.0259 - accuracy: 0.9950\n",
            "Epoch 79/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.0368 - accuracy: 0.9849\n",
            "Epoch 80/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.0336 - accuracy: 0.9899\n",
            "Epoch 81/100\n",
            "7/7 [==============================] - 0s 23ms/step - loss: 0.0927 - accuracy: 0.9899\n",
            "Epoch 82/100\n",
            "7/7 [==============================] - 0s 21ms/step - loss: 0.0454 - accuracy: 0.9950\n",
            "Epoch 83/100\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 0.0292 - accuracy: 0.9950\n",
            "Epoch 84/100\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 0.0273 - accuracy: 0.9950\n",
            "Epoch 85/100\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.0219 - accuracy: 0.9950\n",
            "Epoch 86/100\n",
            "7/7 [==============================] - 0s 21ms/step - loss: 0.0217 - accuracy: 0.9899\n",
            "Epoch 87/100\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 0.0228 - accuracy: 0.9950\n",
            "Epoch 88/100\n",
            "7/7 [==============================] - 0s 24ms/step - loss: 0.0187 - accuracy: 0.9950\n",
            "Epoch 89/100\n",
            "7/7 [==============================] - 0s 22ms/step - loss: 0.0219 - accuracy: 0.9950\n",
            "Epoch 90/100\n",
            "7/7 [==============================] - 0s 21ms/step - loss: 0.0187 - accuracy: 0.9950\n",
            "Epoch 91/100\n",
            "7/7 [==============================] - 0s 21ms/step - loss: 0.0193 - accuracy: 0.9950\n",
            "Epoch 92/100\n",
            "7/7 [==============================] - 0s 22ms/step - loss: 0.0182 - accuracy: 0.9899\n",
            "Epoch 93/100\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 0.0176 - accuracy: 0.9950\n",
            "Epoch 94/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.0167 - accuracy: 0.9950\n",
            "Epoch 95/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.0174 - accuracy: 0.9899\n",
            "Epoch 96/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.0184 - accuracy: 0.9899\n",
            "Epoch 97/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.0171 - accuracy: 0.9950\n",
            "Epoch 98/100\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.0173 - accuracy: 0.9899\n",
            "Epoch 99/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.0482 - accuracy: 0.9849\n",
            "Epoch 100/100\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.0358 - accuracy: 0.9899\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def buildPhrase(inp_str, str_len = 50):\n",
        "  for i in range(str_len):\n",
        "    x = []\n",
        "    for j in range(i, i+inp_chars):\n",
        "      x.append(tokenizer.texts_to_matrix(inp_str[j])) # преобразуем символы в One-Hot-encoding\n",
        "\n",
        "    x = np.array(x)\n",
        "    inp = x.reshape(1, inp_chars, num_characters)\n",
        "\n",
        "    pred = model.predict( inp ) # предсказываем OHE четвертого символа\n",
        "    d = tokenizer.index_word[pred.argmax(axis=1)[0]] # получаем ответ в символьном представлении\n",
        "\n",
        "    inp_str += d # дописываем строку\n",
        "\n",
        "  return inp_str"
      ],
      "metadata": {
        "id": "S8i4Oyu8jkNV"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res = buildPhrase(\"утренн\")\n",
        "print(res)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fbvDV2skjo2g",
        "outputId": "0ebeead1-337a-4a2f-d2db-f92e89f08cde"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 230ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "утренновтовн  и верьте в свою способность достигать отли\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Слова"
      ],
      "metadata": {
        "id": "TVcmjybyjvdO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, SimpleRNN, Dense"
      ],
      "metadata": {
        "id": "6x4sHnKSJeFi"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('train_data.txt', 'r', encoding='utf-8') as f:\n",
        "    texts = f.read()\n",
        "    texts = texts.replace('\\ufeff', '')"
      ],
      "metadata": {
        "id": "Pm5MfQ1qEDXt"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "54KaFLVoQHsL",
        "outputId": "d6eeb890-b966-49cf-8510-e6f6958230ae"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Вы — лучший ответ на проблемы, которые возникли в понедельник.\\nДумайте позитивно и верьте в свою способность достигать отличных результатов.\\nЕсли вы смогли в понедельник подняться с постели, значит вы супер герой.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "maxWordsCount = 1000\n",
        "tokenizer = Tokenizer(num_words=maxWordsCount, filters='!–\" —#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n\\r«»', lower=True, split=' ', char_level=False)\n",
        "\n",
        "tokenizer.fit_on_texts([texts])"
      ],
      "metadata": {
        "id": "YoP6dxr8BZdL"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequences = tokenizer.texts_to_sequences([texts])[0]\n",
        "vocab_size = len(tokenizer.word_index) + 1"
      ],
      "metadata": {
        "id": "DHjJMcuqMHyt"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tvvP37PZQL1M",
        "outputId": "22173b36-ad41-47cb-a32a-2e5430cf665d"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1,\n",
              " 4,\n",
              " 5,\n",
              " 6,\n",
              " 7,\n",
              " 8,\n",
              " 9,\n",
              " 2,\n",
              " 3,\n",
              " 10,\n",
              " 11,\n",
              " 12,\n",
              " 13,\n",
              " 2,\n",
              " 14,\n",
              " 15,\n",
              " 16,\n",
              " 17,\n",
              " 18,\n",
              " 19,\n",
              " 1,\n",
              " 20,\n",
              " 2,\n",
              " 3,\n",
              " 21,\n",
              " 22,\n",
              " 23,\n",
              " 24,\n",
              " 1,\n",
              " 25,\n",
              " 26]"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YqS7F3KsQPX8",
        "outputId": "36b80817-ccef-468f-ed5d-f594b67d9026"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "27"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inp_words = 3\n",
        "X = []\n",
        "Y = []\n",
        "for i in range(len(sequences) - inp_words):\n",
        "    X.append(sequences[i:i + inp_words])\n",
        "    Y.append(sequences[i + inp_words])\n",
        "\n",
        "X = np.array(X)\n",
        "Y = np.array(Y)"
      ],
      "metadata": {
        "id": "t8ZM63GyJoia"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LYjsJRx_PqT0",
        "outputId": "f67fddfe-628f-401c-ee13-1bf6b9a58b78"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1,  4,  5],\n",
              "       [ 4,  5,  6],\n",
              "       [ 5,  6,  7],\n",
              "       [ 6,  7,  8],\n",
              "       [ 7,  8,  9],\n",
              "       [ 8,  9,  2],\n",
              "       [ 9,  2,  3],\n",
              "       [ 2,  3, 10],\n",
              "       [ 3, 10, 11],\n",
              "       [10, 11, 12],\n",
              "       [11, 12, 13],\n",
              "       [12, 13,  2],\n",
              "       [13,  2, 14],\n",
              "       [ 2, 14, 15],\n",
              "       [14, 15, 16],\n",
              "       [15, 16, 17],\n",
              "       [16, 17, 18],\n",
              "       [17, 18, 19],\n",
              "       [18, 19,  1],\n",
              "       [19,  1, 20],\n",
              "       [ 1, 20,  2],\n",
              "       [20,  2,  3],\n",
              "       [ 2,  3, 21],\n",
              "       [ 3, 21, 22],\n",
              "       [21, 22, 23],\n",
              "       [22, 23, 24],\n",
              "       [23, 24,  1],\n",
              "       [24,  1, 25]])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KtHB4wdlPs_5",
        "outputId": "12ac3ed5-b2e1-472d-a899-4237f9b79d15"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 6,  7,  8,  9,  2,  3, 10, 11, 12, 13,  2, 14, 15, 16, 17, 18, 19,\n",
              "        1, 20,  2,  3, 21, 22, 23, 24,  1, 25, 26])"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential([\n",
        "    Embedding(vocab_size, 50, input_length=inp_words),\n",
        "    SimpleRNN(128),\n",
        "    Dense(vocab_size, activation='softmax')\n",
        "])"
      ],
      "metadata": {
        "id": "3giKe_EZJzFO"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "NrRSGvQpJ3jf"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X, Y, batch_size=32, epochs=20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5WTO4pylMfr6",
        "outputId": "75248ec8-f623-41ee-e6e3-63e087d134f3"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1/1 [==============================] - 2s 2s/step - loss: 3.2980 - accuracy: 0.0357\n",
            "Epoch 2/20\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 3.2684 - accuracy: 0.0714\n",
            "Epoch 3/20\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 3.2388 - accuracy: 0.2143\n",
            "Epoch 4/20\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 3.2089 - accuracy: 0.3929\n",
            "Epoch 5/20\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 3.1786 - accuracy: 0.5714\n",
            "Epoch 6/20\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 3.1476 - accuracy: 0.6429\n",
            "Epoch 7/20\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 3.1157 - accuracy: 0.6786\n",
            "Epoch 8/20\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 3.0826 - accuracy: 0.7500\n",
            "Epoch 9/20\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 3.0482 - accuracy: 0.8929\n",
            "Epoch 10/20\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 3.0122 - accuracy: 0.8929\n",
            "Epoch 11/20\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 2.9744 - accuracy: 0.8571\n",
            "Epoch 12/20\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 2.9345 - accuracy: 0.8571\n",
            "Epoch 13/20\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.8923 - accuracy: 0.8571\n",
            "Epoch 14/20\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 2.8477 - accuracy: 0.8571\n",
            "Epoch 15/20\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 2.8003 - accuracy: 0.8929\n",
            "Epoch 16/20\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 2.7500 - accuracy: 0.8929\n",
            "Epoch 17/20\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 2.6965 - accuracy: 0.8929\n",
            "Epoch 18/20\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.6397 - accuracy: 0.8571\n",
            "Epoch 19/20\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.5793 - accuracy: 0.8571\n",
            "Epoch 20/20\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 2.5153 - accuracy: 0.8571\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from keras.preprocessing.sequence import pad_sequences"
      ],
      "metadata": {
        "id": "ZJKo9D1XNOJn"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def buildPhrase(text, model, tokenizer, max_len=20):\n",
        "    result = text.lower()\n",
        "    input_text = text\n",
        "    for _ in range(max_len):\n",
        "        sequence = tokenizer.texts_to_sequences([input_text])[0]\n",
        "        sequence = pad_sequences([sequence], maxlen=inp_words, padding='pre')\n",
        "        pred = model.predict(sequence)\n",
        "        pred_index = np.argmax(pred)\n",
        "        pred_word = tokenizer.index_word[pred_index]\n",
        "        result += \" \" + pred_word\n",
        "        input_text = input_text.split()[1:] + [pred_word]\n",
        "        input_text = ' '.join(input_text)\n",
        "    return result"
      ],
      "metadata": {
        "id": "K8rFYptwMmoR"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "initial_text = \"позитив добавляет годы\"\n",
        "predicted_phrase = buildPhrase(initial_text, model, tokenizer)\n",
        "print(predicted_phrase)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SvqS4gkXMqxJ",
        "outputId": "523e4b6a-7438-4175-d8bd-b2ce070d7bd0"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 253ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "позитив добавляет годы в в понедельник подняться с постели значит вы супер герой понедельник в в понедельник подняться с постели значит вы супер\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "В данном коде реализована функция buildPhrase, которая использует рекуррентную нейронную сеть для создания последовательности слов на основе заданного текста. Основные этапы выполнения этой функции включают:\n",
        "\n",
        "Подготовку входных данных: Исходный текст приводится к нижнему регистру для стандартизации данных и токенизируется с использованием токенизатора, связанного с моделью.\n",
        "\n",
        "Генерацию слов: Затем осуществляется цикл, в котором предсказывается следующее слово в последовательности. Текущая последовательность слов преобразуется в токены и производится предсказание с помощью модели.\n",
        "\n",
        "Обновление данных: Предсказанное слово добавляется к сгенерированной последовательности, затем входной текст обновляется путем удаления первого слова и добавления предсказанного.\n",
        "\n",
        "Завершение цикла: Этот процесс повторяется до достижения заданной длины последовательности или критерия останова.\n",
        "\n",
        "Возврат результата: В конце функции возвращается сгенерированная последовательность слов.\n",
        "\n",
        "Таким образом, функция buildPhrase эффективно использует рекуррентную нейронную сеть для генерации текста на основе обученных данных и представляет собой удобный инструмент для автоматического создания текста с помощью модели и токенизатора."
      ],
      "metadata": {
        "id": "eYCr2As0xfXo"
      }
    }
  ]
}